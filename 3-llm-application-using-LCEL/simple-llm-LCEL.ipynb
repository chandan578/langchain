{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b402c388",
   "metadata": {},
   "source": [
    "### LLM Applications using LCEL(LangChain Expression Language)\n",
    "\n",
    "### Build a Simple LLM Application with LCEL\n",
    "In this quickstart we'll show you how to build a simple LLM application with LangChain. This application will translate text from English into another language. This is a relatively simple LLM application - it's just a single LLM call plus some prompting. Still, this is a great way to get started with LangChain - a lot of features can be built with just some prompting and an LLM call!\n",
    "\n",
    "After seeing this video, you'll have a high level overview of:\n",
    "\n",
    "- Using language models\n",
    "\n",
    "- Using PromptTemplates and OutputParsers\n",
    "\n",
    "- Using LangChain Expression Language (LCEL) to chain components together\n",
    "\n",
    "- Debugging and tracing your application using LangSmith\n",
    "\n",
    "- Deploying your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "575979c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## using openAI and Groq AI\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab40b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Coding\\AI_ML_DL\\langchain\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x00000243FF1B2D70>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000243FF1B2C80>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model='llama-3.1-8b-instant', groq_api_key=groq_api_key)\n",
    "# model = ChatGroq(model='openai/gpt-oss-120b', groq_api_key=groq_api_key)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd31c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Bonjour, comment allez-vous ?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 48, 'total_tokens': 56, 'completion_time': 0.01907485, 'completion_tokens_details': None, 'prompt_time': 0.003673395, 'prompt_tokens_details': None, 'queue_time': 0.056766495, 'total_time': 0.022748245}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b90d3-7dd4-7411-8e4e-e570faca8aa2-0', usage_metadata={'input_tokens': 48, 'output_tokens': 8, 'total_tokens': 56})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content='Translate the following from English to French'),\n",
    "    HumanMessage(content='Hello, How are you?')\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c43389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='नमस्ते, मैं ठीक हूँ।', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 48, 'total_tokens': 61, 'completion_time': 0.023110272, 'completion_tokens_details': None, 'prompt_time': 0.06581711, 'prompt_tokens_details': None, 'queue_time': 0.11520434, 'total_time': 0.088927382}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b90d3-7ec8-7913-84be-92d759434547-0', usage_metadata={'input_tokens': 48, 'output_tokens': 13, 'total_tokens': 61})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "messages = [\n",
    "    SystemMessage(content='Translate the following from English to Hindi'),\n",
    "    HumanMessage(content='Hello, How are you?')\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf2bdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='नमस्ते, मैं ठीक हूँ, धन्यवाद।', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 48, 'total_tokens': 65, 'completion_time': 0.02823876, 'completion_tokens_details': None, 'prompt_time': 0.003422197, 'prompt_tokens_details': None, 'queue_time': 0.051428542, 'total_time': 0.031660957}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b90d3-7fe0-7ab2-b276-c3ae6c1598b6-0', usage_metadata={'input_tokens': 48, 'output_tokens': 17, 'total_tokens': 65})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55bebf79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते, मैं ठीक हूँ, धन्यवाद।'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "parser.invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cac4e481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते, आप कैसे हैं?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using LCEL - chain the component\n",
    "\n",
    "chain = model | parser\n",
    "\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b3fe66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompt template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "generic_prompt = \"Translate the following into {language}\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([('system', generic_prompt), ('user', '{text}')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a956947",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = prompt.invoke({'language':'Hindi', 'text':'Hello'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "066f97b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following into Hindi', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cc89892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({'language':'Hindi', 'text':'Hello'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3981d40b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
